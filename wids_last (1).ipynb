{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUO67nsCa4OJ",
        "outputId": "8d2dd417-1e4f-4755-cc16-c99276033f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "TIL Detection and Segmentation Pipeline for Breast Cancer Histopathology\n",
        "Author: [Your Name]\n",
        "Date: [Current Date]\n",
        "Task: TIGER Challenge Task 1 - Lymphocyte Detection and Segmentation\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import efficientnet_b4\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ==================== CONFIGURATION ====================\n",
        "class Config:\n",
        "    # Data parameters\n",
        "    data_dir = \"./wsi_roi_images\"\n",
        "    img_size = 512\n",
        "    batch_size = 8\n",
        "    num_workers = 2\n",
        "\n",
        "    # Model parameters\n",
        "    backbone = 'efficientnet-b4'\n",
        "    num_classes = 3  # Background, Lymphocyte, Other cells\n",
        "\n",
        "    # Training parameters\n",
        "    num_epochs = 30\n",
        "    learning_rate = 1e-4\n",
        "    weight_decay = 1e-5\n",
        "\n",
        "    # Paths\n",
        "    checkpoint_dir = \"./checkpoints\"\n",
        "    log_dir = \"./logs\"\n",
        "\n",
        "    # Loss weights\n",
        "    seg_weight = 0.7\n",
        "    det_weight = 0.3\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# ==================== CUSTOM UNET IMPLEMENTATION ====================\n",
        "class ConvBlock(nn.Module):\n",
        "    \"\"\"Convolutional block with batch normalization and ReLU\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UpConv(nn.Module):\n",
        "    \"\"\"Upsampling block\"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_channels, out_channels,\n",
        "                                    kernel_size=2, stride=2)\n",
        "        self.conv = ConvBlock(out_channels * 2, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # Pad x1 to match x2 dimensions if needed\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = nn.functional.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                                   diffY // 2, diffY - diffY // 2])\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class CustomUNet(nn.Module):\n",
        "    \"\"\"Custom U-Net implementation\"\"\"\n",
        "    def __init__(self, in_channels=3, num_classes=3):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder (downsampling path)\n",
        "        self.enc1 = ConvBlock(in_channels, 64)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.enc2 = ConvBlock(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.enc3 = ConvBlock(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.enc4 = ConvBlock(256, 512)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = ConvBlock(512, 1024)\n",
        "\n",
        "        # Decoder (upsampling path)\n",
        "        self.up4 = UpConv(1024, 512)\n",
        "        self.up3 = UpConv(512, 256)\n",
        "        self.up2 = UpConv(256, 128)\n",
        "        self.up1 = UpConv(128, 64)\n",
        "\n",
        "        # Output layer\n",
        "        self.out_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "        e4 = self.enc4(self.pool3(e3))\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(self.pool4(e4))\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        d4 = self.up4(b, e4)\n",
        "        d3 = self.up3(d4, e3)\n",
        "        d2 = self.up2(d3, e2)\n",
        "        d1 = self.up1(d2, e1)\n",
        "\n",
        "        # Output\n",
        "        return self.out_conv(d1)\n",
        "\n",
        "# ==================== DATA PREPROCESSING ====================\n",
        "class StainNormalizer:\n",
        "    \"\"\"Reinhard stain normalization for H&E images\"\"\"\n",
        "    def __init__(self, target_image=None):\n",
        "        self.target_means = None\n",
        "        self.target_stds = None\n",
        "        if target_image is not None:\n",
        "            self.fit(target_image)\n",
        "\n",
        "    def fit(self, target_image):\n",
        "        \"\"\"Fit normalization parameters to target image\"\"\"\n",
        "        target_image = cv2.cvtColor(target_image, cv2.COLOR_RGB2LAB)\n",
        "        self.target_means = np.mean(target_image, axis=(0, 1))\n",
        "        self.target_stds = np.std(target_image, axis=(0, 1))\n",
        "\n",
        "    def transform(self, image):\n",
        "        \"\"\"Apply stain normalization to image\"\"\"\n",
        "        if self.target_means is None:\n",
        "            return image\n",
        "\n",
        "        image_lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
        "        image_means = np.mean(image_lab, axis=(0, 1))\n",
        "        image_stds = np.std(image_lab, axis=(0, 1))\n",
        "\n",
        "        # Normalize each channel\n",
        "        for i in range(3):\n",
        "            image_lab[:,:,i] = ((image_lab[:,:,i] - image_means[i]) *\n",
        "                              (self.target_stds[i] / image_stds[i]) +\n",
        "                              self.target_means[i])\n",
        "\n",
        "        # Clip values to valid range\n",
        "        image_lab = np.clip(image_lab, 0, 255).astype(np.uint8)\n",
        "        return cv2.cvtColor(image_lab, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "# ==================== DATASET CLASS ====================\n",
        "class TILDataset(Dataset):\n",
        "    \"\"\"Dataset for TIL detection and segmentation\"\"\"\n",
        "    def __init__(self, image_paths, mask_paths=None, bbox_paths=None,\n",
        "                 is_train=True, stain_norm=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.bbox_paths = bbox_paths\n",
        "        self.is_train = is_train\n",
        "        self.stain_norm = stain_norm\n",
        "\n",
        "        # Define augmentations\n",
        "        if is_train:\n",
        "            self.transform = A.Compose([\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.VerticalFlip(p=0.5),\n",
        "                A.RandomRotate90(p=0.5),\n",
        "                A.ColorJitter(brightness=0.1, contrast=0.1,\n",
        "                            saturation=0.1, hue=0.05, p=0.5),\n",
        "                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.3),\n",
        "                A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "                A.CoarseDropout(max_holes=8, max_height=32,\n",
        "                              max_width=32, fill_value=0, p=0.3),\n",
        "                A.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                          std=(0.229, 0.224, 0.225)),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "        else:\n",
        "            self.transform = A.Compose([\n",
        "                A.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                          std=(0.229, 0.224, 0.225)),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image\n",
        "        image_path = self.image_paths[idx]\n",
        "        try:\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is None:\n",
        "                raise ValueError(f\"Could not read image: {image_path}\")\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {image_path}: {e}\")\n",
        "            # Return a dummy image if loading fails\n",
        "            image = np.ones((512, 512, 3), dtype=np.uint8) * 255\n",
        "\n",
        "        # Apply stain normalization if provided\n",
        "        if self.stain_norm is not None:\n",
        "            image = self.stain_norm.transform(image)\n",
        "\n",
        "        # Initialize mask and bboxes\n",
        "        mask = None\n",
        "        bboxes = []\n",
        "\n",
        "        # Load mask if available\n",
        "        if self.mask_paths is not None and self.mask_paths[idx] is not None:\n",
        "            mask_path = self.mask_paths[idx]\n",
        "            try:\n",
        "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "                if mask is not None:\n",
        "                    # Resize mask if needed\n",
        "                    if mask.shape != (512, 512):\n",
        "                        mask = cv2.resize(mask, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
        "                    mask = (mask > 0).astype(np.uint8)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading mask {mask_path}: {e}\")\n",
        "                mask = np.zeros((512, 512), dtype=np.uint8)\n",
        "\n",
        "        # Load bounding boxes if available\n",
        "        if self.bbox_paths is not None and self.bbox_paths[idx] is not None:\n",
        "            bbox_path = self.bbox_paths[idx]\n",
        "            bboxes = self._load_bboxes(bbox_path)\n",
        "\n",
        "        # Apply augmentations\n",
        "        if self.is_train:\n",
        "            if mask is not None:\n",
        "                transformed = self.transform(image=image, mask=mask)\n",
        "                image = transformed['image']\n",
        "                mask = transformed['mask']\n",
        "            else:\n",
        "                transformed = self.transform(image=image)\n",
        "                image = transformed['image']\n",
        "        else:\n",
        "            transformed = self.transform(image=image)\n",
        "            image = transformed['image']\n",
        "            if mask is not None:\n",
        "                mask = torch.from_numpy(mask).float()\n",
        "\n",
        "        # Prepare output dictionary\n",
        "        sample = {\n",
        "            'image': image,\n",
        "            'image_path': image_path\n",
        "        }\n",
        "\n",
        "        if mask is not None:\n",
        "            sample['mask'] = mask.long() if isinstance(mask, torch.Tensor) else torch.from_numpy(mask).long()\n",
        "\n",
        "        if len(bboxes) > 0:\n",
        "            sample['bboxes'] = torch.tensor(bboxes, dtype=torch.float32)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def _load_bboxes(self, bbox_path):\n",
        "        \"\"\"Load bounding boxes from annotation file\"\"\"\n",
        "        bboxes = []\n",
        "        try:\n",
        "            if os.path.exists(bbox_path):\n",
        "                with open(bbox_path, 'r') as f:\n",
        "                    for line in f:\n",
        "                        if line.strip():\n",
        "                            # Assuming format: x_min,y_min,x_max,y_max,class\n",
        "                            coords = list(map(float, line.strip().split(',')))\n",
        "                            if len(coords) >= 4:\n",
        "                                # Normalize coordinates to [0, 1]\n",
        "                                normalized_coords = [\n",
        "                                    coords[0] / 512.0,\n",
        "                                    coords[1] / 512.0,\n",
        "                                    coords[2] / 512.0,\n",
        "                                    coords[3] / 512.0\n",
        "                                ]\n",
        "                                bboxes.append(normalized_coords[:4])\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading bboxes {bbox_path}: {e}\")\n",
        "        return bboxes\n",
        "\n",
        "# ==================== MODEL ARCHITECTURE ====================\n",
        "class TILDetectionSegmentationModel(nn.Module):\n",
        "    \"\"\"Multi-task model for TIL detection and segmentation\"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # Segmentation model (Custom U-Net)\n",
        "        self.segmentation_model = CustomUNet(\n",
        "            in_channels=3,\n",
        "            num_classes=config.num_classes\n",
        "        )\n",
        "\n",
        "        # Detection head (using EfficientNet features)\n",
        "        encoder = efficientnet_b4(pretrained=True)\n",
        "        self.backbone = nn.Sequential(*list(encoder.children())[:-2])\n",
        "\n",
        "        # Detection layers\n",
        "        self.detection_head = nn.Sequential(\n",
        "            nn.Conv2d(1792, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(64, 4)  # 4 coordinates for bounding box\n",
        "        )\n",
        "\n",
        "        # Confidence score\n",
        "        self.confidence_head = nn.Sequential(\n",
        "            nn.Linear(1792, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Segmentation\n",
        "        seg_output = self.segmentation_model(x)\n",
        "\n",
        "        # Detection features\n",
        "        features = self.backbone(x)\n",
        "\n",
        "        # Detection\n",
        "        bbox_pred = self.detection_head(features)\n",
        "\n",
        "        # Confidence score\n",
        "        pooled_features = nn.functional.adaptive_avg_pool2d(features, (1, 1))\n",
        "        pooled_features = pooled_features.view(pooled_features.size(0), -1)\n",
        "        confidence = self.confidence_head(pooled_features)\n",
        "\n",
        "        return {\n",
        "            'segmentation': seg_output,\n",
        "            'bboxes': bbox_pred,\n",
        "            'confidence': confidence\n",
        "        }\n",
        "\n",
        "# ==================== LOSS FUNCTIONS ====================\n",
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"Dice Loss for segmentation\"\"\"\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super().__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = torch.softmax(pred, dim=1)\n",
        "\n",
        "        # Convert target to one-hot encoding\n",
        "        target_one_hot = torch.zeros_like(pred)\n",
        "        target_one_hot.scatter_(1, target.unsqueeze(1), 1)\n",
        "\n",
        "        # Calculate Dice for each class (skip background)\n",
        "        dice = 0\n",
        "        for class_idx in range(1, pred.shape[1]):\n",
        "            pred_class = pred[:, class_idx]\n",
        "            target_class = target_one_hot[:, class_idx]\n",
        "\n",
        "            intersection = (pred_class * target_class).sum()\n",
        "            union = pred_class.sum() + target_class.sum()\n",
        "\n",
        "            dice += (2. * intersection + self.smooth) / (union + self.smooth)\n",
        "\n",
        "        return 1 - (dice / (pred.shape[1] - 1))\n",
        "\n",
        "class MultiTaskLoss(nn.Module):\n",
        "    \"\"\"Combined loss for segmentation and detection\"\"\"\n",
        "    def __init__(self, seg_weight=0.7, det_weight=0.3):\n",
        "        super().__init__()\n",
        "        self.seg_weight = seg_weight\n",
        "        self.det_weight = det_weight\n",
        "\n",
        "        # Segmentation losses\n",
        "        self.dice_loss = DiceLoss()\n",
        "        self.ce_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Detection losses\n",
        "        self.bbox_loss = nn.SmoothL1Loss()\n",
        "        self.confidence_loss = nn.BCELoss()\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        losses = {}\n",
        "\n",
        "        # Segmentation loss\n",
        "        if 'segmentation' in predictions and 'mask' in targets:\n",
        "            seg_pred = predictions['segmentation']\n",
        "            seg_target = targets['mask']\n",
        "\n",
        "            dice_loss = self.dice_loss(seg_pred, seg_target)\n",
        "            ce_loss = self.ce_loss(seg_pred, seg_target)\n",
        "\n",
        "            # Weighted combination\n",
        "            seg_total_loss = 0.5 * dice_loss + 0.5 * ce_loss\n",
        "            losses['segmentation_loss'] = seg_total_loss\n",
        "            losses['dice_loss'] = dice_loss\n",
        "            losses['ce_loss'] = ce_loss\n",
        "        else:\n",
        "            seg_total_loss = torch.tensor(0.0).to(predictions['segmentation'].device)\n",
        "\n",
        "        # Detection loss\n",
        "        if 'bboxes' in predictions and 'bboxes' in targets:\n",
        "            bbox_pred = predictions['bboxes']\n",
        "            bbox_target = targets['bboxes']\n",
        "            confidence_pred = predictions['confidence']\n",
        "\n",
        "            # Bounding box regression loss\n",
        "            bbox_reg_loss = self.bbox_loss(bbox_pred, bbox_target)\n",
        "\n",
        "            # Confidence loss (use target confidence if available, else assume 1)\n",
        "            confidence_target = targets.get('confidence', torch.ones_like(confidence_pred))\n",
        "            confidence_loss = self.confidence_loss(confidence_pred, confidence_target)\n",
        "\n",
        "            det_total_loss = 0.7 * bbox_reg_loss + 0.3 * confidence_loss\n",
        "            losses['detection_loss'] = det_total_loss\n",
        "            losses['bbox_loss'] = bbox_reg_loss\n",
        "            losses['confidence_loss'] = confidence_loss\n",
        "        else:\n",
        "            det_total_loss = torch.tensor(0.0).to(predictions['segmentation'].device)\n",
        "\n",
        "        # Total weighted loss\n",
        "        total_loss = self.seg_weight * seg_total_loss + self.det_weight * det_total_loss\n",
        "        losses['total_loss'] = total_loss\n",
        "\n",
        "        return losses\n",
        "\n",
        "# ==================== METRICS CALCULATION ====================\n",
        "def calculate_metrics(predictions, targets):\n",
        "    \"\"\"Calculate evaluation metrics\"\"\"\n",
        "    metrics = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Segmentation metrics\n",
        "        if 'segmentation' in predictions and 'mask' in targets:\n",
        "            seg_pred = predictions['segmentation'].argmax(dim=1)\n",
        "            seg_target = targets['mask']\n",
        "\n",
        "            # Calculate per-class IoU\n",
        "            for class_idx in range(1, 3):  # Skip background\n",
        "                pred_mask = (seg_pred == class_idx).float()\n",
        "                target_mask = (seg_target == class_idx).float()\n",
        "\n",
        "                intersection = (pred_mask * target_mask).sum()\n",
        "                union = pred_mask.sum() + target_mask.sum() - intersection\n",
        "\n",
        "                if union > 0:\n",
        "                    iou = intersection / union\n",
        "                    metrics[f'iou_class_{class_idx}'] = iou.item()\n",
        "\n",
        "            # Calculate Dice coefficient\n",
        "            dice = (2 * intersection) / (pred_mask.sum() + target_mask.sum() + 1e-6)\n",
        "            metrics['dice'] = dice.item()\n",
        "\n",
        "        # Detection metrics\n",
        "        if 'bboxes' in predictions and 'bboxes' in targets:\n",
        "            bbox_pred = predictions['bboxes']\n",
        "            bbox_target = targets['bboxes']\n",
        "\n",
        "            if bbox_pred.numel() > 0 and bbox_target.numel() > 0:\n",
        "                # Calculate L1 distance\n",
        "                l1_distance = torch.abs(bbox_pred - bbox_target).mean()\n",
        "                metrics['bbox_l1'] = l1_distance.item()\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# ==================== TRAINING PIPELINE ====================\n",
        "class TILTrainer:\n",
        "    \"\"\"Main training pipeline\"\"\"\n",
        "    def __init__(self, config, model, train_loader, val_loader=None):\n",
        "        self.config = config\n",
        "        self.model = model.to(device)\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "\n",
        "        # Loss function\n",
        "        self.criterion = MultiTaskLoss(\n",
        "            seg_weight=config.seg_weight,\n",
        "            det_weight=config.det_weight\n",
        "        )\n",
        "\n",
        "        # Optimizer\n",
        "        self.optimizer = optim.AdamW(\n",
        "            self.model.parameters(),\n",
        "            lr=config.learning_rate,\n",
        "            weight_decay=config.weight_decay\n",
        "        )\n",
        "\n",
        "        # Learning rate scheduler\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            self.optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
        "        )\n",
        "\n",
        "        # Metrics tracking\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.train_metrics = []\n",
        "        self.val_metrics = []\n",
        "        self.best_val_loss = float('inf')\n",
        "\n",
        "        # Create checkpoint directory\n",
        "        os.makedirs(config.checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        self.model.train()\n",
        "        epoch_losses = {\n",
        "            'total_loss': 0,\n",
        "            'segmentation_loss': 0,\n",
        "            'detection_loss': 0,\n",
        "            'dice_loss': 0,\n",
        "            'ce_loss': 0\n",
        "        }\n",
        "\n",
        "        pbar = tqdm(self.train_loader, desc=f'Train Epoch {epoch}')\n",
        "        for batch_idx, batch in enumerate(pbar):\n",
        "            # Move data to device\n",
        "            images = batch['image'].to(device)\n",
        "\n",
        "            # Prepare targets\n",
        "            targets = {}\n",
        "            if 'mask' in batch:\n",
        "                targets['mask'] = batch['mask'].to(device)\n",
        "            if 'bboxes' in batch:\n",
        "                targets['bboxes'] = batch['bboxes'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(images)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss_dict = self.criterion(outputs, targets)\n",
        "            loss = loss_dict['total_loss']\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "\n",
        "            # Optimizer step\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # Update metrics\n",
        "            for key in epoch_losses:\n",
        "                if key in loss_dict:\n",
        "                    epoch_losses[key] += loss_dict[key].item()\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({\n",
        "                'loss': loss.item(),\n",
        "                'seg': loss_dict.get('segmentation_loss', 0).item(),\n",
        "                'det': loss_dict.get('detection_loss', 0).item()\n",
        "            })\n",
        "\n",
        "        # Calculate average losses\n",
        "        avg_losses = {key: value / len(self.train_loader) for key, value in epoch_losses.items()}\n",
        "        self.train_losses.append(avg_losses['total_loss'])\n",
        "\n",
        "        return avg_losses\n",
        "\n",
        "    def validate(self):\n",
        "        \"\"\"Validation step\"\"\"\n",
        "        if self.val_loader is None:\n",
        "            return None, None\n",
        "\n",
        "        self.model.eval()\n",
        "        val_losses = {\n",
        "            'total_loss': 0,\n",
        "            'segmentation_loss': 0,\n",
        "            'detection_loss': 0\n",
        "        }\n",
        "\n",
        "        all_metrics = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pbar = tqdm(self.val_loader, desc='Validation')\n",
        "            for batch in pbar:\n",
        "                images = batch['image'].to(device)\n",
        "\n",
        "                targets = {}\n",
        "                if 'mask' in batch:\n",
        "                    targets['mask'] = batch['mask'].to(device)\n",
        "                if 'bboxes' in batch:\n",
        "                    targets['bboxes'] = batch['bboxes'].to(device)\n",
        "\n",
        "                outputs = self.model(images)\n",
        "                loss_dict = self.criterion(outputs, targets)\n",
        "\n",
        "                # Calculate metrics\n",
        "                metrics = calculate_metrics(outputs, targets)\n",
        "                all_metrics.append(metrics)\n",
        "\n",
        "                # Update losses\n",
        "                for key in val_losses:\n",
        "                    if key in loss_dict:\n",
        "                        val_losses[key] += loss_dict[key].item()\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    'loss': loss_dict['total_loss'].item()\n",
        "                })\n",
        "\n",
        "        # Calculate average losses and metrics\n",
        "        avg_losses = {key: value / len(self.val_loader) for key, value in val_losses.items()}\n",
        "        self.val_losses.append(avg_losses['total_loss'])\n",
        "\n",
        "        # Aggregate metrics\n",
        "        avg_metrics = {}\n",
        "        if all_metrics:\n",
        "            for key in all_metrics[0].keys():\n",
        "                values = [m[key] for m in all_metrics if key in m]\n",
        "                if values:\n",
        "                    avg_metrics[key] = np.mean(values)\n",
        "\n",
        "        return avg_losses, avg_metrics\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Main training loop\"\"\"\n",
        "        print(\"Starting training...\")\n",
        "        print(f\"Training on {len(self.train_loader.dataset)} samples\")\n",
        "        if self.val_loader:\n",
        "            print(f\"Validating on {len(self.val_loader.dataset)} samples\")\n",
        "\n",
        "        for epoch in range(self.config.num_epochs):\n",
        "            # Train for one epoch\n",
        "            train_losses = self.train_epoch(epoch)\n",
        "\n",
        "            # Validate\n",
        "            if self.val_loader:\n",
        "                val_losses, val_metrics = self.validate()\n",
        "\n",
        "                # Update learning rate\n",
        "                self.scheduler.step(val_losses['total_loss'])\n",
        "\n",
        "                # Save best model\n",
        "                if val_losses['total_loss'] < self.best_val_loss:\n",
        "                    self.best_val_loss = val_losses['total_loss']\n",
        "                    self.save_checkpoint(f'best_model.pth', epoch, val_losses['total_loss'])\n",
        "\n",
        "                # Print epoch summary\n",
        "                print(f\"\\nEpoch {epoch} Summary:\")\n",
        "                print(f\"Train Loss: {train_losses['total_loss']:.4f} | \"\n",
        "                      f\"Val Loss: {val_losses['total_loss']:.4f}\")\n",
        "                print(f\"Train Seg: {train_losses.get('segmentation_loss', 0):.4f} | \"\n",
        "                      f\"Train Det: {train_losses.get('detection_loss', 0):.4f}\")\n",
        "\n",
        "                if val_metrics:\n",
        "                    print(\"Validation Metrics:\")\n",
        "                    for key, value in val_metrics.items():\n",
        "                        print(f\"  {key}: {value:.4f}\")\n",
        "            else:\n",
        "                print(f\"\\nEpoch {epoch}: Train Loss: {train_losses['total_loss']:.4f}\")\n",
        "\n",
        "            # Save checkpoint every 5 epochs\n",
        "            if (epoch + 1) % 5 == 0:\n",
        "                self.save_checkpoint(f'checkpoint_epoch_{epoch+1}.pth', epoch)\n",
        "\n",
        "        # Save final model\n",
        "        self.save_checkpoint('final_model.pth', self.config.num_epochs - 1)\n",
        "        print(\"\\nTraining completed!\")\n",
        "\n",
        "        # Plot training curves\n",
        "        self.plot_training_curves()\n",
        "\n",
        "    def save_checkpoint(self, filename, epoch=None, val_loss=None):\n",
        "        \"\"\"Save model checkpoint\"\"\"\n",
        "        checkpoint_path = os.path.join(self.config.checkpoint_dir, filename)\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'train_losses': self.train_losses,\n",
        "            'val_losses': self.val_losses,\n",
        "            'config': self.config.__dict__\n",
        "        }\n",
        "\n",
        "        if val_loss is not None:\n",
        "            checkpoint['val_loss'] = val_loss\n",
        "\n",
        "        torch.save(checkpoint, checkpoint_path)\n",
        "        print(f\"Checkpoint saved: {checkpoint_path}\")\n",
        "\n",
        "    def load_checkpoint(self, filename):\n",
        "        \"\"\"Load model checkpoint\"\"\"\n",
        "        checkpoint_path = os.path.join(self.config.checkpoint_dir, filename)\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.train_losses = checkpoint['train_losses']\n",
        "        self.val_losses = checkpoint['val_losses']\n",
        "\n",
        "        print(f\"Checkpoint loaded from epoch {checkpoint['epoch']}\")\n",
        "        return checkpoint['epoch']\n",
        "\n",
        "    def plot_training_curves(self):\n",
        "        \"\"\"Plot training and validation losses\"\"\"\n",
        "        plt.figure(figsize=(10, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.train_losses, label='Training Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        if self.val_losses:\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.plot(self.val_losses, label='Validation Loss', color='orange')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.title('Validation Loss')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(self.config.checkpoint_dir, 'training_curves.png'))\n",
        "        plt.show()\n",
        "\n",
        "# ==================== VISUALIZATION ====================\n",
        "def visualize_predictions(model, dataloader, num_samples=3):\n",
        "    \"\"\"Visualize model predictions\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4 * num_samples))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(dataloader):\n",
        "            if idx >= num_samples:\n",
        "                break\n",
        "\n",
        "            images = batch['image'].to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Get predictions\n",
        "            seg_pred = outputs['segmentation'][0].argmax(dim=0).cpu().numpy()\n",
        "\n",
        "            # Original image\n",
        "            img = images[0].cpu().permute(1, 2, 0).numpy()\n",
        "            img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "            img = np.clip(img, 0, 1)\n",
        "\n",
        "            axes[idx, 0].imshow(img)\n",
        "            axes[idx, 0].set_title('Original Image')\n",
        "            axes[idx, 0].axis('off')\n",
        "\n",
        "            # Segmentation prediction\n",
        "            axes[idx, 1].imshow(seg_pred, cmap='jet', alpha=0.7)\n",
        "            axes[idx, 1].set_title('Segmentation Prediction')\n",
        "            axes[idx, 1].axis('off')\n",
        "\n",
        "            # Overlay\n",
        "            axes[idx, 2].imshow(img)\n",
        "            axes[idx, 2].imshow(seg_pred, cmap='jet', alpha=0.5)\n",
        "            axes[idx, 2].set_title('Overlay')\n",
        "            axes[idx, 2].axis('off')\n",
        "\n",
        "            # Ground truth (if available)\n",
        "            if 'mask' in batch:\n",
        "                mask = batch['mask'][0].cpu().numpy()\n",
        "                axes[idx, 3].imshow(mask, cmap='jet', alpha=0.7)\n",
        "                axes[idx, 3].set_title('Ground Truth')\n",
        "            else:\n",
        "                axes[idx, 3].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ==================== DATA LOADING UTILITIES ====================\n",
        "def load_dataset_paths(data_dir):\n",
        "    \"\"\"Load image, mask, and bbox paths from directory\"\"\"\n",
        "    image_files = []\n",
        "    mask_files = []\n",
        "    bbox_files = []\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Warning: Data directory {data_dir} does not exist.\")\n",
        "        print(\"Creating dummy dataset for demonstration...\")\n",
        "        return create_dummy_dataset()\n",
        "\n",
        "    # Walk through directory structure\n",
        "    for root, dirs, files in os.walk(data_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff')):\n",
        "                # Skip mask files\n",
        "                if '_mask' in file.lower() or 'mask_' in file.lower():\n",
        "                    continue\n",
        "\n",
        "                image_path = os.path.join(root, file)\n",
        "                image_files.append(image_path)\n",
        "\n",
        "                # Look for corresponding mask file\n",
        "                base_name = os.path.splitext(file)[0]\n",
        "                mask_path = os.path.join(root, f\"{base_name}_mask.png\")\n",
        "\n",
        "                if os.path.exists(mask_path):\n",
        "                    mask_files.append(mask_path)\n",
        "                else:\n",
        "                    # Try other common mask naming conventions\n",
        "                    mask_path = os.path.join(root, f\"mask_{base_name}.png\")\n",
        "                    if os.path.exists(mask_path):\n",
        "                        mask_files.append(mask_path)\n",
        "                    else:\n",
        "                        mask_files.append(None)\n",
        "\n",
        "                # Look for corresponding bbox file\n",
        "                bbox_path = os.path.join(root, f\"{base_name}_bbox.txt\")\n",
        "                if os.path.exists(bbox_path):\n",
        "                    bbox_files.append(bbox_path)\n",
        "                else:\n",
        "                    bbox_path = os.path.join(root, f\"{base_name}.txt\")\n",
        "                    if os.path.exists(bbox_path):\n",
        "                        bbox_files.append(bbox_path)\n",
        "                    else:\n",
        "                        bbox_files.append(None)\n",
        "\n",
        "    print(f\"Found {len(image_files)} images\")\n",
        "    print(f\"Found {len([m for m in mask_files if m is not None])} masks\")\n",
        "    print(f\"Found {len([b for b in bbox_files if b is not None])} bbox files\")\n",
        "\n",
        "    return image_files, mask_files, bbox_files\n",
        "\n",
        "def create_dummy_dataset():\n",
        "    \"\"\"Create a dummy dataset for demonstration when no real data is available\"\"\"\n",
        "    print(\"Creating dummy dataset with synthetic data...\")\n",
        "\n",
        "    # Create dummy data directory structure\n",
        "    dummy_dir = \"./dummy_data\"\n",
        "    os.makedirs(dummy_dir, exist_ok=True)\n",
        "\n",
        "    image_files = []\n",
        "    mask_files = []\n",
        "    bbox_files = []\n",
        "\n",
        "    # Create 50 dummy samples\n",
        "    for i in range(50):\n",
        "        # Create random image\n",
        "        img = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)\n",
        "\n",
        "        # Create random mask (simulating lymphocytes)\n",
        "        mask = np.zeros((512, 512), dtype=np.uint8)\n",
        "\n",
        "        # Add some random \"lymphocytes\" (small circles)\n",
        "        num_cells = np.random.randint(5, 20)\n",
        "        for _ in range(num_cells):\n",
        "            x = np.random.randint(50, 462)\n",
        "            y = np.random.randint(50, 462)\n",
        "            radius = np.random.randint(3, 8)\n",
        "            cv2.circle(mask, (x, y), radius, 1, -1)\n",
        "\n",
        "        # Add some \"tumor\" regions\n",
        "        num_tumors = np.random.randint(1, 3)\n",
        "        for _ in range(num_tumors):\n",
        "            x = np.random.randint(100, 412)\n",
        "            y = np.random.randint(100, 412)\n",
        "            width = np.random.randint(30, 80)\n",
        "            height = np.random.randint(30, 80)\n",
        "            cv2.rectangle(mask, (x, y), (x+width, y+height), 2, -1)\n",
        "\n",
        "        # Save files\n",
        "        img_path = os.path.join(dummy_dir, f\"sample_{i:03d}.png\")\n",
        "        mask_path = os.path.join(dummy_dir, f\"sample_{i:03d}_mask.png\")\n",
        "        bbox_path = os.path.join(dummy_dir, f\"sample_{i:03d}_bbox.txt\")\n",
        "\n",
        "        cv2.imwrite(img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "        cv2.imwrite(mask_path, mask * 85)  # Scale for visibility\n",
        "\n",
        "        # Create dummy bbox file\n",
        "        with open(bbox_path, 'w') as f:\n",
        "            for _ in range(np.random.randint(1, 5)):\n",
        "                x1 = np.random.randint(0, 500)\n",
        "                y1 = np.random.randint(0, 500)\n",
        "                x2 = x1 + np.random.randint(10, 50)\n",
        "                y2 = y1 + np.random.randint(10, 50)\n",
        "                f.write(f\"{x1},{y1},{x2},{y2},0\\n\")\n",
        "\n",
        "        image_files.append(img_path)\n",
        "        mask_files.append(mask_path)\n",
        "        bbox_files.append(bbox_path)\n",
        "\n",
        "    print(f\"Created dummy dataset with {len(image_files)} samples\")\n",
        "    return image_files, mask_files, bbox_files\n",
        "\n",
        "# ==================== MAIN EXECUTION ====================\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"TIL Detection and Segmentation Pipeline\")\n",
        "    print(\"TIGER Challenge Task\")"
      ]
    }
  ]
}